{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from together import Together\n",
    "import os\n",
    "import json\n",
    "load_dotenv()\n",
    "client = Together()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are the operator of a runaway trolley hurtling down a track. Ahead, five workers are tied to the track and unable to move. If you do nothing, the trolley will kill all five workers. However, you notice a lever that can divert the trolley onto a different track. On this second track, there is one worker tied down who would be killed instead.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethical_choice(fw):\n",
    "    if fw == \"d\":\n",
    "        res = \"Prioritize deontological ethics and tell the course of action.\"\n",
    "    elif fw == \"u\":\n",
    "        res = \"Prioritize utilitarian ethics and tell the course of action.\"\n",
    "    elif fw == \"v\":\n",
    "        res = \"Prioritize virtue ethics and tell the course of action.\"\n",
    "    else:\n",
    "        res = \"Tell the course of action\"\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt+ ethical_choice(\"d\") +\"\"\" Always respond in JSON as \\{\"response\": model_response\\} where model_response is the response from model\"\"\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'From a deontological ethics perspective, which emphasizes the importance of moral rules and duties, the primary consideration is the moral principle of not actively causing harm or taking an action that results in the death of another person. In this scenario, diverting the trolley onto the second track would involve actively causing the death of one worker, even though it would save the lives of the five workers on the original track. According to deontological ethics, particularly as argued by philosophers like Immanuel Kant, it is morally wrong to use a person as a means to an end, even if the end is a good one. Therefore, the deontological approach would suggest that you should not pull the lever, as doing so would involve actively causing the death of one person, and instead, you should not interfere, allowing the events to unfold without your direct intervention, even though this leads to the death of the five workers. This stance prioritizes the adherence to moral rules over the consequences of the action.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
